package com.aexp.gmdl.data.processor.verticle;

import static com.aexp.gmdl.data.processor.config.ConfigExtractor.extractAddressModernizationProcessorConfig;
import static com.aexp.gmdl.data.processor.constants.AppConstants.*;
import static com.aexp.gmdl.data.processor.constants.EventBusConstants.*;
import static com.aexp.gmdl.data.validator.constants.AppConstants.UPSERT_EVENT;

import com.aexp.gmdl.data.processor.constants.AppConstants;
import com.aexp.gmdl.data.processor.constants.EventBusConstants;
import com.aexp.gmdl.data.processor.handler.AddressModernizationHandler;
import com.aexp.gmdl.data.processor.service.MessageSubscriberService;
import com.aexp.gmdl.db.component.service.TransactionalReferenceDataService;
import com.aexp.gmdl.kafka.component.service.KafkaPublisherService;
import io.vertx.core.AbstractVerticle;
import io.vertx.core.CompositeFuture;
import io.vertx.core.Future;
import io.vertx.core.Promise;
import io.vertx.core.eventbus.Message;
import io.vertx.core.eventbus.MessageConsumer;
import io.vertx.core.json.JsonArray;
import io.vertx.core.json.JsonObject;
import io.vertx.serviceproxy.ServiceException;
import java.time.Duration;
import java.time.Instant;
import java.util.ArrayList;
import java.util.List;
import java.util.Map;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

public class AddressModernizationProcessorVerticle extends AbstractVerticle {

  private static final Logger LOGGER =
      LoggerFactory.getLogger(AddressModernizationProcessorVerticle.class);
  private MessageSubscriberService consumerService;
  private AddressModernizationHandler addressModernizationHandler;
  private TransactionalReferenceDataService transactionalReferenceDataService;

  @Override
  public void start(Promise<Void> startPromise) {
    try {
      Map<String, JsonObject> addressModernizationProcessorConfig =
          extractAddressModernizationProcessorConfig(config());
      var publisherService = KafkaPublisherService.create(vertx, config());

      consumerService =
          MessageSubscriberService.createProxy(vertx, MessageSubscriberService.EB_SERVICE_NAME);

      this.transactionalReferenceDataService =
          TransactionalReferenceDataService.create(vertx, config(), null);

      addressModernizationHandler =
          new AddressModernizationHandler(
              config(), transactionalReferenceDataService, publisherService, vertx);

      // Address Modernization processor
      subscribingKafka(
          addressModernizationProcessorConfig
              .get(AppConstants.MER_AD_501_MODERNIZATION)
              .getString(AppConstants.CONFIG_CDC_KAFKA_TOPIC),
          addressModernizationProcessorConfig.get(AppConstants.MER_AD_501_MODERNIZATION),
          EventBusConstants.CDC_MER_AD_501_MODERNIZATION_EB);

      subscribingKafka(
          addressModernizationProcessorConfig
              .get(MER_AD)
              .getString(AppConstants.CONFIG_CDC_KAFKA_TOPIC),
          addressModernizationProcessorConfig.get(MER_AD),
          EventBusConstants.CDC_MER_AD);

      processData(EventBusConstants.CDC_MER_AD_501_MODERNIZATION_EB);
      processData(EventBusConstants.CDC_MER_AD);
      processDataRetry(EventBusConstants.CDC_MER_AD_811_EB_RETRY);
      processDataRetry(EventBusConstants.CDC_MER_AD_503_EB_RETRY);
      processDataRetry(EventBusConstants.CDC_CDC_MER_AD_501_EB_RETRY);

      startPromise.complete();
    } catch (Exception e) {
      LOGGER.error(
          "Error while starting AddressModernizationProcessorVerticle: {}",
          e.getLocalizedMessage());
      startPromise.complete();
      // TEMPORARY FIX to ALLOW RETRY VERTICLE START
      // startPromise.fail(e);
    }
  }

  private void subscribingKafka(String consumerTopic, JsonObject config, String address) {
    consumerService
        .createMessageSubscriber(
            consumerTopic, address, AppConstants.DEFAULT_CONSUMER_POLL_TIMEOUT_MS, config)
        .onSuccess(
            v ->
                LOGGER.info(
                    "Successfully subscribed the CDC Kafka topic for address modernization : {} ",
                    address))
        .onFailure(error -> handleError(consumerTopic, error, address));
  }

  private void processData(String address) {
    Instant begin = Instant.now();
    MessageConsumer<JsonObject> response = vertx.eventBus().<JsonObject>consumer(address);
    response.handler(
        vertxMsg -> {
          JsonObject amqpMsgPayload = vertxMsg.body();
          if (amqpMsgPayload != null) {
            handleMessage(vertxMsg, address)
                .onSuccess(
                    rows -> {
                      LOGGER.info(
                          "{} - Address Data processing success,dataProcessingDuration:{},address:{}",
                          DP_SVC_ADDRESS_PROCESSING_SUCCESS,
                          Duration.between(begin, Instant.now()).getNano() / 1000000,
                          address);

                      vertxMsg.reply(
                          AppConstants.SUCCESS_MSG_REPLY
                              .put(AppConstants.KEY_ADDRESS, address)
                              .put("rows", rows));
                    })
                .onFailure(
                    error -> {
                      // TODO :- JsonArray having Only failure records in records
                      LOGGER.error(
                          "{} - address:{}, Error Response from handler , localizedMessage: {}, cause: {}",
                          DP_SVC_ADDRESS_PROCESSING_FAILURE,
                          address,
                          error.getLocalizedMessage(),
                          error.getCause());

                      vertxMsg.reply(
                          AppConstants.FAILURE_MSG_REPLY
                              .put(AppConstants.KEY_ADDRESS, address)
                              .put(AppConstants.FAILED_REASON, error.getLocalizedMessage()));
                    });
          } else {
            LOGGER.error(
                "{}: Obtained null while polling CDC Kafka Topic : {}",
                DP_KAFKA_ERROR_KEY,
                address);
            vertxMsg.reply(
                AppConstants.FAILURE_MSG_REPLY
                    .put(AppConstants.KEY_ADDRESS, address)
                    .put(
                        AppConstants.FAILED_REASON,
                        DP_KAFKA_ERROR_KEY
                            + ": Obtained null while polling CDC Kafka Topic : {}"
                            + address));
          }
        });
  }

  private void processDataRetry(String addressRetry) {
    Instant begin = Instant.now();
    MessageConsumer<JsonObject> response = vertx.eventBus().<JsonObject>consumer(addressRetry);
    response.handler(
        vertxMsg -> {
          JsonObject amqpMsgPayload = vertxMsg.body();
          if (amqpMsgPayload != null) {
            handleMessage(vertxMsg, addressRetry)
                .onSuccess(
                    rows -> {
                      LOGGER.info(
                          "{} - Address Data processing success,dataProcessingDuration:{},address:{}",
                          DP_SVC_ADDRESS_PROCESSING_RETRY_SUCCESS,
                          Duration.between(begin, Instant.now()).getNano() / 1000000,
                          addressRetry);
                      vertxMsg.reply(
                          AppConstants.SUCCESS_MSG_REPLY
                              .put(AppConstants.KEY_ADDRESS, addressRetry)
                              .put("rows", rows));
                    }) // TODO:- No need to send whole data
                .onFailure(
                    error -> {
                      // TODO :- JsonArray having Only failure records in records
                      LOGGER.error(
                          "{} - address:{}, Error Response from handler , localizedMessage: {}, cause: {}",
                          DP_SVC_ADDRESS_PROCESSING_RETRY_FAILURE,
                          addressRetry,
                          error.getLocalizedMessage(),
                          error.getCause());

                      vertxMsg.reply(
                          AppConstants.FAILURE_MSG_REPLY
                              .put(AppConstants.KEY_ADDRESS, addressRetry)
                              .put(AppConstants.FAILED_REASON, error.getLocalizedMessage()));
                    });

          } else {
            LOGGER.error(
                "{}: Obtained null while polling CDC Kafka Topic : {}",
                DP_KAFKA_ERROR_KEY,
                addressRetry);
            vertxMsg.reply(
                AppConstants.FAILURE_MSG_REPLY
                    .put(AppConstants.KEY_ADDRESS, addressRetry)
                    .put(
                        AppConstants.FAILED_REASON,
                        DP_KAFKA_ERROR_KEY
                            + ": Obtained null while polling CDC Kafka Topic : {}"
                            + addressRetry));
          }
        });
  }

  private void setTableNameForRetry(JsonObject row, String retryAddress) {
    if (retryAddress.equals(CDC_CDC_MER_AD_501_EB_RETRY)) {
      row.put(TABLE_NAME, "TC501_MER_PRIM_CHAR_DTL");
    } else if (retryAddress.equals(CDC_MER_AD_503_EB_RETRY)) {
      row.put(TABLE_NAME, "TC503_MER_PSTL_AD");
    } else if (retryAddress.equals(CDC_MER_AD_811_EB_RETRY)) {
      row.put(TABLE_NAME, "TG811_MER_LOC_LANG_AD");
    }
  }

  private Future<JsonArray> handleMessage(Message<JsonObject> msg, String address) {
    JsonObject msgJson = msg.body();

    JsonArray rows = msgJson.getJsonArray("rows");
    JsonObject distributedRows = new JsonObject();
    Promise<JsonArray> promise = Promise.promise();

    rows.stream()
        .map(JsonObject.class::cast)
        .forEach(
            row -> {
              if (row.getString(EVENT_UNDERSCORE_TYPE).equals(UPSERT_EVENT)) {
                if (address.contains("-retry")) {
                  setTableNameForRetry(row, address);
                }
                if (distributedRows.getJsonArray(row.getString("table_name")) == null) {
                  distributedRows.put(row.getString("table_name"), new JsonArray());
                }
                distributedRows.getJsonArray(row.getString("table_name")).add(row);
              } else {
                LOGGER.warn(
                    "BatchCorrelationId: {}, Address: {}, received DELETE event {}",
                    msgJson.getString(CORRELATION_UNDERSCORE_ID),
                    address,
                    row);
              }
            });

    if (!distributedRows.isEmpty()) {
      List<Future> futureList = new ArrayList<>();
      distributedRows.stream()
          .forEach(
              batch -> {
                futureList.add(
                    this.addressModernizationHandler.handle(
                        getDependentTable(batch.getKey(), address),
                        new JsonObject()
                            .put("rows", batch.getValue())
                            .put("correlation_id", msgJson.getString("correlation_id"))));
              });

      CompositeFuture.all(futureList)
          .onSuccess(
              res -> {
                JsonArray response = new JsonArray();
                res.result().list().stream()
                    .forEach(
                        resp -> {
                          if (resp != null) {
                            JsonArray list = (JsonArray) resp;
                            list.forEach(response::add);
                          }
                        });
                promise.complete(response);
              })
          .onFailure(promise::fail);
    } else {
      promise.complete(rows);
    }

    return promise.future();
  }

  private void handleError(String consumerTopic, Throwable error, String address) {
    LOGGER.error(
        "{}: while processing the polling. Cause: {},address:{}, Trace: {}",
        DP_KAFKA_ERROR_KEY,
        error.getMessage(),
        address,
        error);
    if (error instanceof ServiceException) {
      ServiceException exc = (ServiceException) error;
      LOGGER.error(
          "{}: while polling the CDC Kafka topic: {}. Detailed Cause: {}",
          DP_KAFKA_ERROR_KEY,
          consumerTopic,
          exc.getDebugInfo());
    }
  }

  @Override
  public void stop(Promise<Void> stopPromise) throws Exception {
    super.stop(stopPromise);
  }

  private String getDependentTable(String address, String ebAddress) {
    String tableName = "";
    switch (address) {
      case "TC503_MER_PSTL_AD":
      case "cdc.mer_ad~503.eb":
        tableName = "cdc.mer_ad~503.eb";
        break;
      case "TC501_MER_PRIM_CHAR_DTL":
      case "cdc.mer_ad~501.eb":
        tableName = "cdc.mer_ad~501.eb";
        break;
      case "TG811_MER_LOC_LANG_AD":
      case "cdc.mer_ad~811.eb":
        tableName = "cdc.mer_ad~811.eb";
        break;
      case "cdc.mer_ad.eb":
        tableName = "cdc.mer_ad.eb";
        break;
      default:
        LOGGER.error(
            "Error while getting the table details from kafka message, Address: {}", address);
        break;
    }
    return ebAddress.contains("-retry") ? tableName + "-retry" : tableName;
  }
}
